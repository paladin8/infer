{
  "use_kv_cache": true,
  "suite": "full",
  "model": "Qwen/Qwen3-1.7B",
  "dtype": "bfloat16",
  "device": "cuda",
  "gpu_name": "NVIDIA GeForce RTX 5080",
  "trials": 3,
  "warmup_runs": 2,
  "pytorch_version": "2.10.0+cu128",
  "cuda_version": "12.8",
  "post_load_gpu_gb": 3.8,
  "post_load_gpu_reserved_gb": 3.81,
  "configs": [
    {
      "use_kv_cache": true,
      "config_name": "short-greedy",
      "model": "Qwen/Qwen3-1.7B",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 64,
      "generated_tokens": 64,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 15.34,
      "prompt_throughput_median_tps": 4172.2,
      "decode_throughput_median_tps": 76.4,
      "e2e_throughput_tps": 75.0,
      "per_step_latency_mean_ms": 13.42,
      "per_step_latency_p50_ms": 13.2,
      "per_step_latency_p95_ms": 14.97,
      "per_step_latency_p99_ms": 18.08,
      "per_step_latency_min_ms": 11.91,
      "per_step_latency_max_ms": 18.62,
      "wall_time_median_s": 0.853,
      "cache_memory_mb": 14.7,
      "post_load_gpu_gb": 3.8,
      "post_load_gpu_reserved_gb": 3.81,
      "end_gpu_memory_gb": 3.81,
      "end_gpu_reserved_gb": 3.84,
      "peak_gpu_memory_gb": 3.83,
      "peak_gpu_reserved_gb": 3.84,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:38:06.012926+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "medium-greedy",
      "model": "Qwen/Qwen3-1.7B",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 256,
      "generated_tokens": 256,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 21.08,
      "prompt_throughput_median_tps": 12142.8,
      "decode_throughput_median_tps": 71.8,
      "e2e_throughput_tps": 71.3,
      "per_step_latency_mean_ms": 14.09,
      "per_step_latency_p50_ms": 13.74,
      "per_step_latency_p95_ms": 16.59,
      "per_step_latency_p99_ms": 19.18,
      "per_step_latency_min_ms": 11.89,
      "per_step_latency_max_ms": 24.1,
      "wall_time_median_s": 3.59,
      "cache_memory_mb": 58.7,
      "post_load_gpu_gb": 3.8,
      "post_load_gpu_reserved_gb": 3.81,
      "end_gpu_memory_gb": 3.81,
      "end_gpu_reserved_gb": 3.9,
      "peak_gpu_memory_gb": 3.88,
      "peak_gpu_reserved_gb": 3.9,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:38:24.203129+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "prefill-heavy",
      "model": "Qwen/Qwen3-1.7B",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 1024,
      "generated_tokens": 64,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 54.16,
      "prompt_throughput_median_tps": 18906.5,
      "decode_throughput_median_tps": 75.1,
      "e2e_throughput_tps": 70.6,
      "per_step_latency_mean_ms": 13.53,
      "per_step_latency_p50_ms": 13.48,
      "per_step_latency_p95_ms": 14.41,
      "per_step_latency_p99_ms": 14.92,
      "per_step_latency_min_ms": 12.05,
      "per_step_latency_max_ms": 16.5,
      "wall_time_median_s": 0.907,
      "cache_memory_mb": 124.8,
      "post_load_gpu_gb": 3.8,
      "post_load_gpu_reserved_gb": 3.81,
      "end_gpu_memory_gb": 3.81,
      "end_gpu_reserved_gb": 4.03,
      "peak_gpu_memory_gb": 3.98,
      "peak_gpu_reserved_gb": 4.03,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:38:28.903838+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "decode-heavy",
      "model": "Qwen/Qwen3-1.7B",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 64,
      "generated_tokens": 1024,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 14.66,
      "prompt_throughput_median_tps": 4364.7,
      "decode_throughput_median_tps": 73.7,
      "e2e_throughput_tps": 73.6,
      "per_step_latency_mean_ms": 13.57,
      "per_step_latency_p50_ms": 13.43,
      "per_step_latency_p95_ms": 14.75,
      "per_step_latency_p99_ms": 16.94,
      "per_step_latency_min_ms": 11.65,
      "per_step_latency_max_ms": 23.64,
      "wall_time_median_s": 13.911,
      "cache_memory_mb": 124.8,
      "post_load_gpu_gb": 3.8,
      "post_load_gpu_reserved_gb": 3.81,
      "end_gpu_memory_gb": 3.81,
      "end_gpu_reserved_gb": 3.96,
      "peak_gpu_memory_gb": 3.94,
      "peak_gpu_reserved_gb": 3.96,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:39:40.565850+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "long-context",
      "model": "Qwen/Qwen3-1.7B",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 1024,
      "generated_tokens": 1024,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 53.27,
      "prompt_throughput_median_tps": 19222.7,
      "decode_throughput_median_tps": 73.9,
      "e2e_throughput_tps": 73.7,
      "per_step_latency_mean_ms": 13.75,
      "per_step_latency_p50_ms": 13.56,
      "per_step_latency_p95_ms": 15.4,
      "per_step_latency_p99_ms": 16.94,
      "per_step_latency_min_ms": 12.03,
      "per_step_latency_max_ms": 27.03,
      "wall_time_median_s": 13.902,
      "cache_memory_mb": 234.9,
      "post_load_gpu_gb": 3.8,
      "post_load_gpu_reserved_gb": 3.81,
      "end_gpu_memory_gb": 3.81,
      "end_gpu_reserved_gb": 4.13,
      "peak_gpu_memory_gb": 4.08,
      "peak_gpu_reserved_gb": 4.13,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:40:51.938029+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "medium-sampled",
      "model": "Qwen/Qwen3-1.7B",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 256,
      "generated_tokens": 256,
      "temperature": 0.8,
      "top_k": 50,
      "top_p": 0.9,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 22.37,
      "prompt_throughput_median_tps": 11443.7,
      "decode_throughput_median_tps": 76.4,
      "e2e_throughput_tps": 75.9,
      "per_step_latency_mean_ms": 13.13,
      "per_step_latency_p50_ms": 13.02,
      "per_step_latency_p95_ms": 14.36,
      "per_step_latency_p99_ms": 16.24,
      "per_step_latency_min_ms": 11.82,
      "per_step_latency_max_ms": 18.44,
      "wall_time_median_s": 3.372,
      "cache_memory_mb": 58.7,
      "post_load_gpu_gb": 3.8,
      "post_load_gpu_reserved_gb": 3.81,
      "end_gpu_memory_gb": 3.81,
      "end_gpu_reserved_gb": 3.9,
      "peak_gpu_memory_gb": 3.88,
      "peak_gpu_reserved_gb": 3.9,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:41:09.638672+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "medium-full-pipeline",
      "model": "Qwen/Qwen3-1.7B",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 256,
      "generated_tokens": 256,
      "temperature": 0.8,
      "top_k": 50,
      "top_p": 0.9,
      "repetition_penalty": 1.1,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 22.03,
      "prompt_throughput_median_tps": 11619.9,
      "decode_throughput_median_tps": 76.3,
      "e2e_throughput_tps": 75.9,
      "per_step_latency_mean_ms": 13.13,
      "per_step_latency_p50_ms": 13.04,
      "per_step_latency_p95_ms": 14.21,
      "per_step_latency_p99_ms": 15.16,
      "per_step_latency_min_ms": 11.76,
      "per_step_latency_max_ms": 19.17,
      "wall_time_median_s": 3.375,
      "cache_memory_mb": 58.7,
      "post_load_gpu_gb": 3.8,
      "post_load_gpu_reserved_gb": 3.81,
      "end_gpu_memory_gb": 3.81,
      "end_gpu_reserved_gb": 3.9,
      "peak_gpu_memory_gb": 3.88,
      "peak_gpu_reserved_gb": 3.9,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:41:27.341108+00:00"
    }
  ],
  "timestamp": "2026-02-21T03:41:27.341214+00:00"
}