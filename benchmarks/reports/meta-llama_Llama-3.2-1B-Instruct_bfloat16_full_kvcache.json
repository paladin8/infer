{
  "use_kv_cache": true,
  "suite": "full",
  "model": "meta-llama/Llama-3.2-1B-Instruct",
  "dtype": "bfloat16",
  "device": "cuda",
  "gpu_name": "NVIDIA GeForce RTX 5080",
  "trials": 3,
  "warmup_runs": 2,
  "pytorch_version": "2.10.0+cu128",
  "cuda_version": "12.8",
  "post_load_gpu_gb": 2.82,
  "post_load_gpu_reserved_gb": 2.83,
  "configs": [
    {
      "use_kv_cache": true,
      "config_name": "short-greedy",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 64,
      "generated_tokens": 64,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 8.01,
      "prompt_throughput_median_tps": 7989.5,
      "decode_throughput_median_tps": 151.4,
      "e2e_throughput_tps": 148.4,
      "per_step_latency_mean_ms": 6.72,
      "per_step_latency_p50_ms": 6.6,
      "per_step_latency_p95_ms": 7.6,
      "per_step_latency_p99_ms": 8.03,
      "per_step_latency_min_ms": 6.03,
      "per_step_latency_max_ms": 9.6,
      "wall_time_median_s": 0.431,
      "cache_memory_mb": 4.2,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.85,
      "peak_gpu_memory_gb": 2.84,
      "peak_gpu_reserved_gb": 2.85,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:36:05.105349+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "medium-greedy",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 256,
      "generated_tokens": 256,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 11.77,
      "prompt_throughput_median_tps": 21742.8,
      "decode_throughput_median_tps": 145.6,
      "e2e_throughput_tps": 144.7,
      "per_step_latency_mean_ms": 7.06,
      "per_step_latency_p50_ms": 6.84,
      "per_step_latency_p95_ms": 8.24,
      "per_step_latency_p99_ms": 9.31,
      "per_step_latency_min_ms": 6.17,
      "per_step_latency_max_ms": 11.41,
      "wall_time_median_s": 1.77,
      "cache_memory_mb": 16.8,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.87,
      "peak_gpu_memory_gb": 2.86,
      "peak_gpu_reserved_gb": 2.87,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:36:14.264361+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "prefill-heavy",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 1024,
      "generated_tokens": 64,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 31.52,
      "prompt_throughput_median_tps": 32485.8,
      "decode_throughput_median_tps": 148.5,
      "e2e_throughput_tps": 138.4,
      "per_step_latency_mean_ms": 6.89,
      "per_step_latency_p50_ms": 6.81,
      "per_step_latency_p95_ms": 7.31,
      "per_step_latency_p99_ms": 9.13,
      "per_step_latency_min_ms": 6.24,
      "per_step_latency_max_ms": 9.6,
      "wall_time_median_s": 0.462,
      "cache_memory_mb": 35.7,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.97,
      "peak_gpu_memory_gb": 2.93,
      "peak_gpu_reserved_gb": 2.97,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:36:16.740225+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "decode-heavy",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 64,
      "generated_tokens": 1024,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 7.79,
      "prompt_throughput_median_tps": 8214.9,
      "decode_throughput_median_tps": 143.7,
      "e2e_throughput_tps": 143.6,
      "per_step_latency_mean_ms": 6.91,
      "per_step_latency_p50_ms": 6.77,
      "per_step_latency_p95_ms": 7.88,
      "per_step_latency_p99_ms": 8.71,
      "per_step_latency_min_ms": 5.85,
      "per_step_latency_max_ms": 13.24,
      "wall_time_median_s": 7.132,
      "cache_memory_mb": 35.7,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.9,
      "peak_gpu_memory_gb": 2.88,
      "peak_gpu_reserved_gb": 2.9,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:36:52.634773+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "long-context",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 1024,
      "generated_tokens": 1024,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 31.13,
      "prompt_throughput_median_tps": 32893.8,
      "decode_throughput_median_tps": 145.0,
      "e2e_throughput_tps": 144.4,
      "per_step_latency_mean_ms": 6.9,
      "per_step_latency_p50_ms": 6.88,
      "per_step_latency_p95_ms": 7.38,
      "per_step_latency_p99_ms": 8.06,
      "per_step_latency_min_ms": 6.15,
      "per_step_latency_max_ms": 9.91,
      "wall_time_median_s": 7.093,
      "cache_memory_mb": 67.1,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 3.0,
      "peak_gpu_memory_gb": 2.96,
      "peak_gpu_reserved_gb": 3.0,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:37:29.129394+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "medium-sampled",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 256,
      "generated_tokens": 256,
      "temperature": 0.8,
      "top_k": 50,
      "top_p": 0.9,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 11.27,
      "prompt_throughput_median_tps": 22719.3,
      "decode_throughput_median_tps": 152.1,
      "e2e_throughput_tps": 151.1,
      "per_step_latency_mean_ms": 6.61,
      "per_step_latency_p50_ms": 6.59,
      "per_step_latency_p95_ms": 7.02,
      "per_step_latency_p99_ms": 7.59,
      "per_step_latency_min_ms": 6.04,
      "per_step_latency_max_ms": 8.53,
      "wall_time_median_s": 1.695,
      "cache_memory_mb": 16.8,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.87,
      "peak_gpu_memory_gb": 2.86,
      "peak_gpu_reserved_gb": 2.87,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:37:38.472075+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "medium-full-pipeline",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 256,
      "generated_tokens": 196,
      "temperature": 0.8,
      "top_k": 50,
      "top_p": 0.9,
      "repetition_penalty": 1.1,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 11.36,
      "prompt_throughput_median_tps": 22541.2,
      "decode_throughput_median_tps": 149.1,
      "e2e_throughput_tps": 147.8,
      "per_step_latency_mean_ms": 6.76,
      "per_step_latency_p50_ms": 6.65,
      "per_step_latency_p95_ms": 7.27,
      "per_step_latency_p99_ms": 9.25,
      "per_step_latency_min_ms": 6.09,
      "per_step_latency_max_ms": 11.07,
      "wall_time_median_s": 1.326,
      "cache_memory_mb": 16.8,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.87,
      "peak_gpu_memory_gb": 2.86,
      "peak_gpu_reserved_gb": 2.87,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T03:37:45.952546+00:00"
    }
  ],
  "timestamp": "2026-02-21T03:37:45.952637+00:00"
}