{
  "use_kv_cache": true,
  "suite": "full",
  "model": "meta-llama/Llama-3.2-1B-Instruct",
  "dtype": "bfloat16",
  "device": "cuda",
  "gpu_name": "NVIDIA GeForce RTX 5080",
  "trials": 3,
  "warmup_runs": 2,
  "pytorch_version": "2.10.0+cu128",
  "cuda_version": "12.8",
  "post_load_gpu_gb": 2.82,
  "post_load_gpu_reserved_gb": 2.83,
  "configs": [
    {
      "use_kv_cache": true,
      "config_name": "short-greedy",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 64,
      "generated_tokens": 64,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 5.38,
      "prompt_throughput_median_tps": 11895.0,
      "decode_throughput_median_tps": 219.0,
      "e2e_throughput_tps": 215.1,
      "per_step_latency_mean_ms": 4.69,
      "per_step_latency_p50_ms": 4.55,
      "per_step_latency_p95_ms": 5.59,
      "per_step_latency_p99_ms": 6.02,
      "per_step_latency_min_ms": 4.23,
      "per_step_latency_max_ms": 6.34,
      "wall_time_median_s": 0.298,
      "cache_memory_mb": 4.2,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.85,
      "peak_gpu_memory_gb": 2.84,
      "peak_gpu_reserved_gb": 2.85,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T09:17:02.120207+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "medium-greedy",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 256,
      "generated_tokens": 256,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 8.46,
      "prompt_throughput_median_tps": 30253.3,
      "decode_throughput_median_tps": 214.8,
      "e2e_throughput_tps": 213.1,
      "per_step_latency_mean_ms": 4.68,
      "per_step_latency_p50_ms": 4.59,
      "per_step_latency_p95_ms": 5.2,
      "per_step_latency_p99_ms": 6.2,
      "per_step_latency_min_ms": 4.3,
      "per_step_latency_max_ms": 7.85,
      "wall_time_median_s": 1.201,
      "cache_memory_mb": 16.8,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.87,
      "peak_gpu_memory_gb": 2.86,
      "peak_gpu_reserved_gb": 2.87,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T09:17:08.346805+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "prefill-heavy",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 1024,
      "generated_tokens": 64,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 29.62,
      "prompt_throughput_median_tps": 34576.6,
      "decode_throughput_median_tps": 213.4,
      "e2e_throughput_tps": 194.2,
      "per_step_latency_mean_ms": 4.76,
      "per_step_latency_p50_ms": 4.67,
      "per_step_latency_p95_ms": 5.2,
      "per_step_latency_p99_ms": 5.77,
      "per_step_latency_min_ms": 4.44,
      "per_step_latency_max_ms": 6.28,
      "wall_time_median_s": 0.33,
      "cache_memory_mb": 35.7,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.97,
      "peak_gpu_memory_gb": 2.93,
      "peak_gpu_reserved_gb": 2.97,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T09:17:10.049627+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "decode-heavy",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 64,
      "generated_tokens": 1024,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 5.31,
      "prompt_throughput_median_tps": 12053.2,
      "decode_throughput_median_tps": 215.1,
      "e2e_throughput_tps": 214.9,
      "per_step_latency_mean_ms": 4.65,
      "per_step_latency_p50_ms": 4.59,
      "per_step_latency_p95_ms": 5.11,
      "per_step_latency_p99_ms": 6.0,
      "per_step_latency_min_ms": 4.16,
      "per_step_latency_max_ms": 8.83,
      "wall_time_median_s": 4.765,
      "cache_memory_mb": 35.7,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.9,
      "peak_gpu_memory_gb": 2.88,
      "peak_gpu_reserved_gb": 2.9,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T09:17:34.598331+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "long-context",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 1024,
      "generated_tokens": 1024,
      "temperature": 0.0,
      "top_k": null,
      "top_p": 1.0,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 28.8,
      "prompt_throughput_median_tps": 35559.1,
      "decode_throughput_median_tps": 209.3,
      "e2e_throughput_tps": 208.1,
      "per_step_latency_mean_ms": 4.78,
      "per_step_latency_p50_ms": 4.73,
      "per_step_latency_p95_ms": 5.24,
      "per_step_latency_p99_ms": 5.79,
      "per_step_latency_min_ms": 4.4,
      "per_step_latency_max_ms": 8.03,
      "wall_time_median_s": 4.921,
      "cache_memory_mb": 67.1,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 3.0,
      "peak_gpu_memory_gb": 2.96,
      "peak_gpu_reserved_gb": 3.0,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T09:17:59.908724+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "medium-sampled",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 256,
      "generated_tokens": 256,
      "temperature": 0.8,
      "top_k": 50,
      "top_p": 0.9,
      "repetition_penalty": 1.0,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 8.9,
      "prompt_throughput_median_tps": 28760.2,
      "decode_throughput_median_tps": 216.0,
      "e2e_throughput_tps": 214.4,
      "per_step_latency_mean_ms": 4.65,
      "per_step_latency_p50_ms": 4.58,
      "per_step_latency_p95_ms": 5.03,
      "per_step_latency_p99_ms": 5.77,
      "per_step_latency_min_ms": 4.3,
      "per_step_latency_max_ms": 6.35,
      "wall_time_median_s": 1.194,
      "cache_memory_mb": 16.8,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.87,
      "peak_gpu_memory_gb": 2.86,
      "peak_gpu_reserved_gb": 2.87,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T09:18:06.669841+00:00"
    },
    {
      "use_kv_cache": true,
      "config_name": "medium-full-pipeline",
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "dtype": "bfloat16",
      "device": "cuda",
      "gpu_name": "NVIDIA GeForce RTX 5080",
      "prompt_tokens": 256,
      "generated_tokens": 197,
      "temperature": 0.8,
      "top_k": 50,
      "top_p": 0.9,
      "repetition_penalty": 1.1,
      "seed": 42,
      "trials": 3,
      "ttft_median_ms": 9.05,
      "prompt_throughput_median_tps": 28275.1,
      "decode_throughput_median_tps": 216.3,
      "e2e_throughput_tps": 214.2,
      "per_step_latency_mean_ms": 4.64,
      "per_step_latency_p50_ms": 4.59,
      "per_step_latency_p95_ms": 5.06,
      "per_step_latency_p99_ms": 5.37,
      "per_step_latency_min_ms": 4.33,
      "per_step_latency_max_ms": 6.4,
      "wall_time_median_s": 0.92,
      "cache_memory_mb": 16.8,
      "post_load_gpu_gb": 2.82,
      "post_load_gpu_reserved_gb": 2.83,
      "end_gpu_memory_gb": 2.83,
      "end_gpu_reserved_gb": 2.87,
      "peak_gpu_memory_gb": 2.86,
      "peak_gpu_reserved_gb": 2.87,
      "pytorch_version": "2.10.0+cu128",
      "cuda_version": "12.8",
      "timestamp": "2026-02-21T09:18:11.920422+00:00"
    }
  ],
  "timestamp": "2026-02-21T09:18:11.920511+00:00"
}